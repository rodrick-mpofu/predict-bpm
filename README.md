# Predicting the Beats-per-Minute of Songs

## Kaggle Playground Series - Season 5, Episode 9

### ğŸµ Project Overview

This repository contains my solution for the Kaggle Playground Series competition focused on predicting the beats-per-minute (BPM) of songs using machine learning techniques. The goal is to build a regression model that accurately predicts a song's tempo from various audio features.

### ğŸ¯ Competition Details

- **Competition Type**: Regression (Continuous Target Variable)
- **Evaluation Metric**: Root Mean Squared Error (RMSE)
- **Timeline**: September 1-30, 2025
- **Dataset**: Synthetically generated from real-world music data

### ğŸ“Š Dataset Information

The dataset contains various audio features that can be used to predict a song's BPM. This is a synthetic dataset created from real-world music data, designed to provide realistic patterns while ensuring test labels remain private.

**Target Variable**: `BeatsPerMinute` - Continuous values representing song tempo

### ğŸ† Competition Goals

- Predict continuous BPM values for songs in the test set
- Minimize Root Mean Squared Error between predictions and actual BPM
- Practice regression techniques and feature engineering
- Explore audio feature relationships with song tempo

### ğŸ“ Repository Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv           # Training dataset with BPM targets
â”‚   â”œâ”€â”€ test.csv            # Test dataset (without target)
â”‚   â””â”€â”€ sample_submission.csv # Competition submission format
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb        # Exploratory Data Analysis âœ…
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â”œâ”€â”€ data_preprocessing.py # Data cleaning and preprocessing âœ…
â”‚   â””â”€â”€ utils.py            # Utility functions and helpers âœ…
â”œâ”€â”€ submissions/
â”‚   â””â”€â”€ ensemble_submission.csv # Generated predictions
â”œâ”€â”€ .gitignore              # Git ignore rules for ML projects âœ…
â”œâ”€â”€ requirements.txt        # Python dependencies âœ…
â””â”€â”€ README.md              # Project documentation
```

### ğŸ› ï¸ Setup and Installation

1. Clone this repository:
```bash
git clone https://github.com/[username]/predict-bpm.git
cd predict-bpm
```

2. Install required packages:
```bash
pip install -r requirements.txt
```

3. Download the competition data from Kaggle and place in the `data/` folder.

### ğŸ§ª Methodology & Progress

#### Data Exploration âœ…
- [x] Analyze distribution of BPM values (completed in EDA notebook)
- [x] Explore feature correlations and relationships
- [x] Identify missing values and outliers
- [x] Visualize audio feature relationships with target
- [x] Statistical analysis of feature distributions

#### Feature Engineering ğŸ”„
- [x] Data preprocessing pipeline implemented
- [x] Missing value handling strategies
- [x] Feature scaling and normalization
- [ ] Create polynomial features
- [ ] Generate interaction terms
- [ ] Domain-specific audio feature engineering

#### Modeling Approach ğŸ“‹
- [ ] Baseline linear regression
- [ ] Random Forest Regressor
- [ ] Gradient Boosting (XGBoost, LightGBM, CatBoost)
- [ ] Neural Networks (if beneficial)
- [ ] Ensemble methods for final predictions

#### Model Validation ğŸ“‹
- [ ] K-fold cross-validation setup
- [ ] Feature importance analysis
- [ ] Hyperparameter tuning with Optuna
- [ ] Model interpretability with SHAP

### ğŸ“ˆ Current Results

| Model | CV Score (RMSE) | Public LB Score |
|-------|----------------|-----------------|
| Baseline | - | - |
| Random Forest | - | - |
| XGBoost | - | - |
| Ensemble | - | - |

### ğŸ”§ Technical Implementation Details

#### Current Architecture
- **Data Pipeline**: Modular preprocessing with `data_preprocessing.py`
- **Utility Functions**: Reusable components in `utils.py` for model evaluation and visualization
- **Notebook-Based EDA**: Comprehensive exploratory analysis in Jupyter notebooks

#### Feature Engineering Strategy
- **Missing Value Handling**: Statistical imputation based on feature distributions
- **Scaling Strategy**: StandardScaler for continuous features, preserving audio feature relationships
- **Feature Selection**: Correlation analysis and domain knowledge for audio features
- **Future Plans**: Polynomial features, interaction terms, and domain-specific transformations

#### Model Development Approach
- **Baseline Strategy**: Start with linear regression for interpretability
- **Tree-Based Models**: Random Forest and Gradient Boosting (XGBoost, LightGBM, CatBoost)
- **Ensemble Strategy**: Weighted averaging and stacking approaches
- **Validation**: Stratified K-fold cross-validation to ensure robust performance estimates

#### Technical Stack
- **Core ML**: scikit-learn ecosystem with gradient boosting libraries
- **Hyperparameter Optimization**: Optuna for efficient parameter search
- **Model Interpretation**: SHAP values for feature importance and model explainability
- **Visualization**: matplotlib/seaborn for EDA, plotly for interactive plots

### ğŸ“‹ Submission Format

Predictions should be submitted in CSV format:
```csv
ID,BeatsPerMinute
524164,119.5
524165,127.42
524166,111.11
```

### ğŸš€ How to Run

1. **Exploratory Data Analysis**:
   ```bash
   jupyter notebook notebooks/01_eda.ipynb
   ```

2. **Training Models**:
   ```bash
   python src/models.py
   ```

3. **Generate Predictions**:
   ```bash
   python src/predict.py
   ```

### ğŸ“š Dependencies

#### Core Data Science Stack
- **pandas** (â‰¥1.5.0) - Data manipulation and analysis
- **numpy** (â‰¥1.21.0) - Numerical computing
- **scikit-learn** (â‰¥1.1.0) - Machine learning algorithms and preprocessing
- **scipy** (â‰¥1.8.0) - Statistical functions
- **statsmodels** (â‰¥0.13.0) - Advanced statistical analysis

#### Machine Learning Libraries
- **xgboost** (â‰¥1.6.0) - Gradient boosting framework
- **lightgbm** (â‰¥3.3.0) - Fast gradient boosting
- **catboost** (â‰¥1.1.0) - Categorical feature handling
- **optuna** (â‰¥3.0.0) - Hyperparameter optimization

#### Visualization & Analysis
- **matplotlib** (â‰¥3.5.0) - Static plotting
- **seaborn** (â‰¥0.11.0) - Statistical visualization
- **plotly** (â‰¥5.10.0) - Interactive visualizations
- **shap** (â‰¥0.41.0) - Model interpretation

#### Development Tools
- **jupyter** (â‰¥1.0.0) - Interactive notebooks
- **tqdm** (â‰¥4.64.0) - Progress bars
- **joblib** (â‰¥1.1.0) - Model persistence
- **feature-engine** (â‰¥1.5.0) - Feature engineering utilities

*See `requirements.txt` for complete dependency list with version specifications.*

### ğŸ¤ Competition Context

This competition is part of the Kaggle Tabular Playground Series, designed to provide:
- Lightweight challenges for skill development
- Synthetic datasets based on real-world data
- Opportunities for rapid experimentation
- Community learning and collaboration

### ğŸ“ Notes

- The dataset is synthetically generated but maintains realistic patterns from actual music data
- Focus on regression techniques and feature engineering
- RMSE optimization is key to achieving good performance
- Cross-validation is crucial for reliable model evaluation

### ğŸ–ï¸ Competition Prizes

- 1st-3rd Place: Choice of Kaggle merchandise
- Focus on learning and community participation

### ğŸ“„ Citation

Walter Reade and Elizabeth Park. Predicting the Beats-per-Minute of Songs. https://kaggle.com/competitions/playground-series-s5e9, 2025. Kaggle.

---

### ğŸ“ Contact

Feel free to reach out for discussions about approaches, feature engineering ideas, or collaboration opportunities!

**Happy Modeling! ğŸµğŸ“Š**